{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=text-align:center;color:brown;font:bold> Data PreProcessing </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divided into 6 parts\n",
    "    * Common Data preparation tasks\n",
    "    * Data Cleaning\n",
    "    * Feature Selection\n",
    "    * Data Transformation\n",
    "    * Feature engineering\n",
    "    * Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=text-align:center;color:blue;font:bold> Data Cleaning </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we will look for, in this notebook:\n",
    "* How to identify and remove column variables that only have a single value\n",
    "* How to identify and remove column variables that have less unique values\n",
    "* How to identify and remove rows that contain duplicate observations\n",
    "\n",
    "<html> \n",
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "</html>\n",
    "\n",
    "Dividing into seven parts :\n",
    "1) Messy Datasets\n",
    "2) Identify Columns That Contain a Single Value \n",
    "3) Delete Columns That Contain a Single Value \n",
    "4) Consider Columns That Have Very Few Values \n",
    "5) Remove Columns That Have A Low Variance \n",
    "6) Identify Rows that Contain Duplicate Data\n",
    "7) Delete Rows that Contain Duplicate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "oilDataPath = \"/Users/manideepbangaru/Documents/EDAnMLApply/Datasets/oil-spill-dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Messy Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv(oilDataPath + \"oil-spill.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify columns that contain a single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     238\n",
      "1     297\n",
      "2     927\n",
      "3     933\n",
      "4     179\n",
      "5     375\n",
      "6     820\n",
      "7     618\n",
      "8     561\n",
      "9      57\n",
      "10    577\n",
      "11     59\n",
      "12     73\n",
      "13    107\n",
      "14     53\n",
      "15     91\n",
      "16    893\n",
      "17    810\n",
      "18    170\n",
      "19     53\n",
      "20     68\n",
      "21      9\n",
      "22      1\n",
      "23     92\n",
      "24      9\n",
      "25      8\n",
      "26      9\n",
      "27    308\n",
      "28    447\n",
      "29    392\n",
      "30    107\n",
      "31     42\n",
      "32      4\n",
      "33     45\n",
      "34    141\n",
      "35    110\n",
      "36      3\n",
      "37    758\n",
      "38      9\n",
      "39      9\n",
      "40    388\n",
      "41    220\n",
      "42    644\n",
      "43    649\n",
      "44    499\n",
      "45      2\n",
      "46    937\n",
      "47    169\n",
      "48    286\n",
      "49      2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# summarize the number of unique values each column has\n",
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete columns that contain a single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 50)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of unique values for each column\n",
    "counts = df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record columns to delete\n",
    "to_del = [i for i,v in enumerate(counts) if v==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22]\n",
      "(937, 49)\n"
     ]
    }
   ],
   "source": [
    "print(to_del)\n",
    "\n",
    "# drop these cols\n",
    "df.drop(to_del, axis=1, inplace=True)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider columns that have very few values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      25.400213\n",
      "1      31.696905\n",
      "2      98.932764\n",
      "3      99.573106\n",
      "4      19.103522\n",
      "5      40.021345\n",
      "6      87.513340\n",
      "7      65.955176\n",
      "8      59.871932\n",
      "9       6.083244\n",
      "10     61.579509\n",
      "11      6.296692\n",
      "12      7.790822\n",
      "13     11.419424\n",
      "14      5.656350\n",
      "15      9.711846\n",
      "16     95.304162\n",
      "17     86.446105\n",
      "18     18.143010\n",
      "19      5.656350\n",
      "20      7.257204\n",
      "21      0.960512\n",
      "23      9.818570\n",
      "24      0.960512\n",
      "25      0.853789\n",
      "26      0.960512\n",
      "27     32.870864\n",
      "28     47.705443\n",
      "29     41.835646\n",
      "30     11.419424\n",
      "31      4.482391\n",
      "32      0.426894\n",
      "33      4.802561\n",
      "34     15.048026\n",
      "35     11.739594\n",
      "36      0.320171\n",
      "37     80.896478\n",
      "38      0.960512\n",
      "39      0.960512\n",
      "40     41.408751\n",
      "41     23.479189\n",
      "42     68.729989\n",
      "43     69.263607\n",
      "44     53.255069\n",
      "45      0.213447\n",
      "46    100.000000\n",
      "47     18.036286\n",
      "48     30.522946\n",
      "49      0.213447\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "valPercentages = (df.nunique()/len(df))*100\n",
    "print(valPercentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterIndexes = [i for i,v in enumerate(valPercentages) if v<=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns\n",
    "df.drop(filterIndexes, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(937, 39)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove columns that have a low variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 38)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# split data into data and outputs\n",
    "X = df.values[:,:-1]\n",
    "y = df.values[:,-1]\n",
    "\n",
    "# defining variance threshold\n",
    "transform = VarianceThreshold()\n",
    "\n",
    "# Transform the input data\n",
    "X_sel = transform.fit_transform(X)\n",
    "\n",
    "print(X_sel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(937, 39)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000000e+00, 2.558000e+03, 1.506090e+03, ..., 3.324319e+04,\n",
       "        6.574000e+01, 1.000000e+00],\n",
       "       [2.000000e+00, 2.232500e+04, 7.911000e+01, ..., 5.157204e+04,\n",
       "        6.573000e+01, 0.000000e+00],\n",
       "       [3.000000e+00, 1.150000e+02, 1.449850e+03, ..., 3.169284e+04,\n",
       "        6.581000e+01, 1.000000e+00],\n",
       "       ...,\n",
       "       [2.020000e+02, 1.400000e+01, 2.514000e+01, ..., 2.153050e+03,\n",
       "        6.591000e+01, 0.000000e+00],\n",
       "       [2.030000e+02, 1.000000e+01, 9.600000e+01, ..., 2.421430e+03,\n",
       "        6.597000e+01, 0.000000e+00],\n",
       "       [2.040000e+02, 1.100000e+01, 7.730000e+00, ..., 3.782680e+03,\n",
       "        6.565000e+01, 0.000000e+00]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cedfd3e4b37a9720fe3b219ed0a866f6a3a20179a0ee2a520f69b6a410e4f49a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.mlenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
